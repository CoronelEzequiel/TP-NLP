{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d95f58bd",
   "metadata": {},
   "source": [
    "# Clasificador de textos políticos - GEMINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d387800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\user_d\\appdata\\roaming\\python\\python311\\site-packages (0.8.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\user_d\\appdata\\roaming\\python\\python311\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\user_d\\appdata\\roaming\\python\\python311\\site-packages (from google-generativeai) (2.24.2)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\user_d\\appdata\\roaming\\python\\python311\\site-packages (from google-generativeai) (2.169.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\user_d\\appdata\\roaming\\python\\python311\\site-packages (from google-generativeai) (2.40.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\user_d\\appdata\\roaming\\python\\python311\\site-packages (from google-generativeai) (5.29.4)\n",
      "Requirement already satisfied: pydantic in c:\\programdata\\anaconda3\\lib\\site-packages (from google-generativeai) (1.10.8)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from google-generativeai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user_d\\appdata\\roaming\\python\\python311\\site-packages (from google-generativeai) (4.14.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\user_d\\appdata\\roaming\\python\\python311\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user_d\\appdata\\roaming\\python\\python311\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user_d\\appdata\\roaming\\python\\python311\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\user_d\\appdata\\roaming\\python\\python311\\site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (2.31.0)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\user_d\\appdata\\roaming\\python\\python311\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\user_d\\appdata\\roaming\\python\\python311\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\user_d\\appdata\\roaming\\python\\python311\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\user_d\\appdata\\roaming\\python\\python311\\site-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\user_d\\appdata\\roaming\\python\\python311\\site-packages (from google-api-core->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\programdata\\anaconda3\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: python-dotenv in c:\\programdata\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\programdata\\anaconda3\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 23.3 will enforce this behaviour change. A possible replacement is to use pip for package installation..\n"
     ]
    }
   ],
   "source": [
    "%pip install google-generativeai\n",
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad89f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# === CONFIGURACIÓN ===\n",
    "CARPETA_ENTRADA = \"textos\"\n",
    "CARPETA_SALIDA = \"resultados\"\n",
    "ARCHIVO_LOG = \"log_errores.txt\"\n",
    "\n",
    "# Inicializar modelo\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Inicializar modelo con parámetros ajustados para mejorar precisión y robustez\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-2.0-flash\",\n",
    "    generation_config={\n",
    "        \"temperature\": 0.8,\n",
    "        \"top_p\": 0.8,\n",
    "        \"top_k\": 40,\n",
    "        \"candidate_count\": 1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ad57ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurar que exista la carpeta de salida\n",
    "os.makedirs(CARPETA_SALIDA, exist_ok=True)\n",
    "\n",
    "# Inicializar archivo de log\n",
    "with open(ARCHIVO_LOG, \"w\", encoding=\"utf-8\") as log:\n",
    "    log.write(\"=== LOG DE ERRORES ===\\n\")\n",
    "\n",
    "# Obtener archivos ya procesados\n",
    "procesados = {\n",
    "    os.path.splitext(f)[0]\n",
    "    for f in os.listdir(CARPETA_SALIDA)\n",
    "    if f.endswith(\".json\")\n",
    "}    \n",
    "\n",
    "# Archivos de entrada (excluyendo los ya procesados)\n",
    "archivos_txt = []\n",
    "for raiz, _, archivos in os.walk(CARPETA_ENTRADA):\n",
    "    for archivo in archivos:\n",
    "        if archivo.endswith(\".txt\"):\n",
    "            nombre_base = os.path.splitext(archivo)[0]\n",
    "            if nombre_base not in procesados:\n",
    "                archivos_txt.append(os.path.join(raiz, archivo))\n",
    "\n",
    "\n",
    "# Token acumulado\n",
    "total_tokens_global = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e01fcd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpretar_score(score):\n",
    "    if score < 0.2:\n",
    "        return \"ultraizquierda\"\n",
    "    elif score < 0.4:\n",
    "        return \"izquierda moderada\"\n",
    "    elif score < 0.6:\n",
    "        return \"neutral\"\n",
    "    elif score < 0.8:\n",
    "        return \"derecha moderada\"\n",
    "    else:\n",
    "        return \"ultraderecha\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d8c4824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Procesado: Es un manicomio - Editorial #VivianaConVos 27072022.txt | Tokens: 8615\n",
      "✅ Procesado: Falta de coraje - Editorial #VivianaConVos 25072022.txt | Tokens: 8717\n",
      "✅ Procesado: Larreta decidió separar boletas y M. Macri está desilusionado  Apertura MF.txt | Tokens: 4025\n",
      "✅ Procesado: Libertad de expresión #VivianaConVos 08082022.txt | Tokens: 3068\n",
      "✅ Procesado: Nada es gratis - Editorial #VivianaConVos 02082022.txt | Tokens: 8657\n",
      "✅ Procesado: Paren de robar - Editorial #VivianaConVos 01082022.txt | Tokens: 7432\n",
      "✅ Procesado: Parole, parole, parole - Editorial #VivianaConVos 26072022.txt | Tokens: 8678\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 40\u001b[0m\n\u001b[0;32m     10\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124mVas a analizar un texto con orientación política en Argentina. Devolvé una respuesta en formato JSON con la siguiente estructura exacta:\u001b[39m\n\u001b[0;32m     12\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtexto\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;130;01m\\\"\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 40\u001b[0m     response \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate_content(prompt)\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# Si el prompt fue bloqueado por Gemini (por contenido sensible u otra política)\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcandidates:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\generativeai\\generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mgenerate_content(\n\u001b[0;32m    332\u001b[0m             request,\n\u001b[0;32m    333\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrequest_options,\n\u001b[0;32m    334\u001b[0m         )\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:835\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m    834\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 835\u001b[0m response \u001b[38;5;241m=\u001b[39m rpc(\n\u001b[0;32m    836\u001b[0m     request,\n\u001b[0;32m    837\u001b[0m     retry\u001b[38;5;241m=\u001b[39mretry,\n\u001b[0;32m    838\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    839\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m    840\u001b[0m )\n\u001b[0;32m    842\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry_target(\n\u001b[0;32m    294\u001b[0m     target,\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicate,\n\u001b[0;32m    296\u001b[0m     sleep_generator,\n\u001b[0;32m    297\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout,\n\u001b[0;32m    298\u001b[0m     on_error\u001b[38;5;241m=\u001b[39mon_error,\n\u001b[0;32m    299\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m target()\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\api_core\\timeout.py:130\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\n\u001b[0;32m    128\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m remaining_timeout\n\u001b[1;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\api_core\\grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(callable_)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_remapped_callable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\grpc\\_interceptor.py:277\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    270\u001b[0m     request: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m--> 277\u001b[0m     response, ignored_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_with_call(\n\u001b[0;32m    278\u001b[0m         request,\n\u001b[0;32m    279\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    280\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m    281\u001b[0m         credentials\u001b[38;5;241m=\u001b[39mcredentials,\n\u001b[0;32m    282\u001b[0m         wait_for_ready\u001b[38;5;241m=\u001b[39mwait_for_ready,\n\u001b[0;32m    283\u001b[0m         compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    284\u001b[0m     )\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\grpc\\_interceptor.py:329\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _FailureOutcome(exception, sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m--> 329\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interceptor\u001b[38;5;241m.\u001b[39mintercept_unary_unary(\n\u001b[0;32m    330\u001b[0m     continuation, client_call_details, request\n\u001b[0;32m    331\u001b[0m )\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call\u001b[38;5;241m.\u001b[39mresult(), call\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\transports\\grpc.py:79\u001b[0m, in \u001b[0;36m_LoggingClientInterceptor.intercept_unary_unary\u001b[1;34m(self, continuation, client_call_details, request)\u001b[0m\n\u001b[0;32m     64\u001b[0m     grpc_request \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpayload\u001b[39m\u001b[38;5;124m\"\u001b[39m: request_payload,\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequestMethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrpc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(request_metadata),\n\u001b[0;32m     68\u001b[0m     }\n\u001b[0;32m     69\u001b[0m     _LOGGER\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_call_details\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     71\u001b[0m         extra\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     76\u001b[0m         },\n\u001b[0;32m     77\u001b[0m     )\n\u001b[1;32m---> 79\u001b[0m response \u001b[38;5;241m=\u001b[39m continuation(client_call_details, request)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logging_enabled:  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     response_metadata \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mtrailing_metadata()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\grpc\\_interceptor.py:315\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[1;34m(new_details, request)\u001b[0m\n\u001b[0;32m    306\u001b[0m (\n\u001b[0;32m    307\u001b[0m     new_method,\n\u001b[0;32m    308\u001b[0m     new_timeout,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    312\u001b[0m     new_compression,\n\u001b[0;32m    313\u001b[0m ) \u001b[38;5;241m=\u001b[39m _unwrap_client_call_details(new_details, client_call_details)\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 315\u001b[0m     response, call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thunk(new_method)\u001b[38;5;241m.\u001b[39mwith_call(\n\u001b[0;32m    316\u001b[0m         request,\n\u001b[0;32m    317\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mnew_timeout,\n\u001b[0;32m    318\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mnew_metadata,\n\u001b[0;32m    319\u001b[0m         credentials\u001b[38;5;241m=\u001b[39mnew_credentials,\n\u001b[0;32m    320\u001b[0m         wait_for_ready\u001b[38;5;241m=\u001b[39mnew_wait_for_ready,\n\u001b[0;32m    321\u001b[0m         compression\u001b[38;5;241m=\u001b[39mnew_compression,\n\u001b[0;32m    322\u001b[0m     )\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m rpc_error:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\grpc\\_channel.py:1195\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.with_call\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwith_call\u001b[39m(\n\u001b[0;32m   1184\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1185\u001b[0m     request: Any,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1190\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1191\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, grpc\u001b[38;5;241m.\u001b[39mCall]:\n\u001b[0;32m   1192\u001b[0m     (\n\u001b[0;32m   1193\u001b[0m         state,\n\u001b[0;32m   1194\u001b[0m         call,\n\u001b[1;32m-> 1195\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blocking(\n\u001b[0;32m   1196\u001b[0m         request, timeout, metadata, credentials, wait_for_ready, compression\n\u001b[0;32m   1197\u001b[0m     )\n\u001b[0;32m   1198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\grpc\\_channel.py:1162\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[1;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[0;32m   1145\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[0;32m   1146\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[0;32m   1147\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_call_handle,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[1;32m-> 1162\u001b[0m event \u001b[38;5;241m=\u001b[39m call\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[0;32m   1163\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[0;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:388\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:211\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/channel.pyx.pxi:205\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:61\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\python\\\\grpcio\\\\grpc\\\\_cython\\\\_cygrpc/completion_queue.pyx.pxi:42\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Procesamiento\n",
    "for ruta_entrada in archivos_txt:\n",
    "    archivo = os.path.basename(ruta_entrada)\n",
    "    subcarpeta = os.path.basename(os.path.dirname(ruta_entrada))  # Esta será la etiqueta_original\n",
    "    ruta_salida = os.path.join(CARPETA_SALIDA, f\"{os.path.splitext(archivo)[0]}.json\")\n",
    "\n",
    "    with open(ruta_entrada, \"r\", encoding=\"utf-8\") as f:\n",
    "        texto = f.read()\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Vas a analizar un texto con orientación política en Argentina. Devolvé una respuesta en formato JSON con la siguiente estructura exacta:\n",
    "\n",
    "    {{\n",
    "      \"texto_id\": \"nombre_del_texto\",\n",
    "      \"etiqueta_original\": \"{subcarpeta}\",\n",
    "      \"perfil_global_del_texto\": {{\n",
    "        \"score_promedio\": \"\",\n",
    "        \"interpretacion\": \"\"\n",
    "      }},\n",
    "      \"frases\": [\n",
    "        {{\n",
    "          \"frase\": \"frase completa\",\n",
    "          \"score\": float entre 0 y 1 indicando cercanía a derecha (0 = izquierda, 1 = derecha),\n",
    "          \"etiqueta\": \"izquierda|derecha|neutral\"\n",
    "        }},\n",
    "        ...\n",
    "      ]\n",
    "    }}\n",
    "\n",
    "    Reglas:\n",
    "    - Extraé frases significativas (mínimo 3).\n",
    "    - Clasificá cada frase individualmente.\n",
    "    - Usá el nombre del archivo sin extensión como \"texto_id\".\n",
    "\n",
    "    Texto a analizar:\n",
    "    \\\"\\\"\\\"{texto}\\\"\\\"\\\"\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = model.generate_content(prompt)\n",
    "\n",
    "        # Si el prompt fue bloqueado por Gemini (por contenido sensible u otra política)\n",
    "        if not response.candidates:\n",
    "            block_reason = getattr(response.prompt_feedback, \"block_reason\", \"UNKNOWN\")\n",
    "            raise ValueError(f\"Prompt bloqueado por política: {block_reason}\")\n",
    "\n",
    "        raw = response.candidates[0].content.parts[0].text.strip()\n",
    "        if raw.startswith(\"```json\"):\n",
    "            raw = raw.removeprefix(\"```json\").removesuffix(\"```\").strip()\n",
    "\n",
    "        total_tokens = getattr(response.usage_metadata, \"total_token_count\", None)\n",
    "        if total_tokens:\n",
    "            total_tokens_global += total_tokens\n",
    "\n",
    "        resultado = json.loads(raw)\n",
    "\n",
    "        # Calcular promedio de score y asignar interpretación\n",
    "        frases = resultado.get(\"frases\", [])\n",
    "        if frases:\n",
    "            promedio = sum(f.get(\"score\", 0) for f in frases) / len(frases)\n",
    "            resultado[\"perfil_global_del_texto\"] = {\n",
    "                \"score_promedio\": round(promedio, 3),\n",
    "                \"interpretacion\": interpretar_score(promedio)\n",
    "            }\n",
    "\n",
    "        if \"texto_id\" not in resultado:\n",
    "            resultado[\"texto_id\"] = os.path.splitext(archivo)[0]\n",
    "\n",
    "        resultado[\"tokens_procesados\"] = total_tokens\n",
    "\n",
    "        with open(ruta_salida, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(resultado, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        print(f\"✅ Procesado: {archivo} | Tokens: {resultado.get('tokens_procesados', 'N/A')}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        total_tokens = getattr(response.usage_metadata, \"total_token_count\", None)\n",
    "        resultado = {\n",
    "            \"texto_id\": os.path.splitext(archivo)[0],\n",
    "            \"error\": str(e),\n",
    "            \"raw_response\": \"\",  # ⚠️ No accedemos a .text si fue bloqueado\n",
    "            \"tokens_procesados\": total_tokens\n",
    "        }\n",
    "        if total_tokens:\n",
    "            total_tokens_global += total_tokens\n",
    "        with open(ARCHIVO_LOG, \"a\", encoding=\"utf-8\") as log:\n",
    "            log.write(f\"❌ Error en {archivo}: {str(e)}\\n\")\n",
    "\n",
    "print(f\"\\n🧠 Total global de tokens procesados: {total_tokens_global}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42584f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def evaluar_predicciones(directorio):\n",
    "    total = 0\n",
    "    aciertos = 0\n",
    "    errores = []\n",
    "\n",
    "    for raiz, _, archivos in os.walk(directorio):\n",
    "        for archivo in archivos:\n",
    "            if archivo.endswith(\".json\"):\n",
    "                path = os.path.join(raiz, archivo)\n",
    "                try:\n",
    "                    with open(path, encoding=\"utf-8\") as f:\n",
    "                        data = json.load(f)\n",
    "\n",
    "                    etiqueta = data.get(\"etiqueta_original\", \"\").lower()\n",
    "                    interpretacion = data.get(\"perfil_global_del_texto\", {}).get(\"interpretacion\", \"\").lower()\n",
    "\n",
    "                    total += 1\n",
    "                    if etiqueta in interpretacion:\n",
    "                        aciertos += 1\n",
    "                    else:\n",
    "                        errores.append({\n",
    "                            \"archivo\": archivo,\n",
    "                            \"etiqueta_original\": etiqueta,\n",
    "                            \"interpretacion\": interpretacion\n",
    "                        })\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Error procesando {archivo}: {e}\")\n",
    "\n",
    "    if total == 0:\n",
    "        print(\"❌ No se encontraron archivos JSON.\")\n",
    "        return\n",
    "\n",
    "    precision = round(aciertos / total * 100, 2)\n",
    "    print(f\"✅ Total archivos analizados: {total}\")\n",
    "    print(f\"🎯 Predicciones correctas: {aciertos}\")\n",
    "    print(f\"❌ Predicciones incorrectas: {total - aciertos}\")\n",
    "    print(f\"📊 Accuracy: {precision}%\")\n",
    "\n",
    "    return {\n",
    "        \"total\": total,\n",
    "        \"aciertos\": aciertos,\n",
    "        \"errores\": errores,\n",
    "        \"Accuracy\": precision\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d713ce87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total archivos analizados: 3100\n",
      "🎯 Predicciones correctas: 2587\n",
      "❌ Predicciones incorrectas: 513\n",
      "📊 Accuracy: 83.45%\n"
     ]
    }
   ],
   "source": [
    "resultados = evaluar_predicciones(\"resultados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcad01c",
   "metadata": {},
   "source": [
    "# Utils - no necesarias para el clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e310d2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def eliminar_jsons_con_error(carpeta_salida):\n",
    "    \"\"\"\n",
    "    Elimina todos los archivos JSON dentro del directorio dado que contengan la clave \"error\".\n",
    "\n",
    "    Parámetros:\n",
    "    - carpeta_salida (str): Ruta al directorio donde están los JSON procesados.\n",
    "\n",
    "    Devuelve:\n",
    "    - int: Cantidad de archivos eliminados.\n",
    "    \"\"\"\n",
    "    eliminados = 0\n",
    "\n",
    "    for archivo in os.listdir(carpeta_salida):\n",
    "        if archivo.endswith(\".json\"):\n",
    "            ruta = os.path.join(carpeta_salida, archivo)\n",
    "            try:\n",
    "                with open(ruta, encoding=\"utf-8\") as f:\n",
    "                    data = json.load(f)\n",
    "                if \"error\" in data:\n",
    "                    os.remove(ruta)\n",
    "                    eliminados += 1\n",
    "                    print(f\"🗑️ Eliminado: {archivo}\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ No se pudo analizar {archivo}: {e}\")\n",
    "\n",
    "    print(f\"\\n✅ Total de archivos eliminados: {eliminados}\")\n",
    "    return eliminados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b5c777",
   "metadata": {},
   "outputs": [],
   "source": [
    "eliminar_jsons_con_error(CARPETA_SALIDA)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
